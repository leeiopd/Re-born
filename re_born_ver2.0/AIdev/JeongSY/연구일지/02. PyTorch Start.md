## PyTorch를 사용해봅시다.

Python 기반의 `과학 연산 패키지`로 다음과 같은 두집단을 대상으로 해요.

* NumPy를 대체하고 GPU의 연산력을 사용
* 유연성과 속도를 제공하는 딥러닝 연구 플랫폼



## 자료형 : Tensor

Tensor는 NumPy의 배열(ndarray)과 유사할뿐만 아니라, GPU를 사용한 연산 가속도를 지원해요. Tensor 자료형 데이터를 만드는 방법은 3가지가 있어요.

* 리스트나 NumPy 배열을 Tensor로 변환
* 0 또는 1 등의 특정한 값을 가진 Tensor를 생성
* 랜덤한 값을 가지는 텐서를 생성
* CUDA Tensors



### 배열과 리스트를 텐서 자료형으로 변환

* `torch.tensor()` : `값 복사 (value copy)`를 사용하며 새로운 tensor 자료형 인스턴스를 생성해요.

* `torch_as_tensor()` : 리스트나 ndarray 객체를 받아요. `값 참조(Reference)`를 사용하여 Tensor 자료형 뷰(View)를 만들어요.

* `torch.from_numpy()`: ndarray 객체를 받아요. `값 참조(Reference)`를 사용하여 Tensor 자료형 뷰(View)를 만들어요.

  ```python
  import numpy as np
  
  li = np.array([[1,2],[3,4]])
  
  li_tensor = torch.tensor(li) // Numpy 배열과 List 가능
  li_as_tensor = torch.as_tensor(li) // Numpy 배열과 List 가능
  li_from_numpy = torch.from_numpy(li) // Numpy 배열이 아닌 그냥 List를 받으면 에러 
  
  print(li_tensor)
  print(li_as_tensor)
  print(li_from_numpy)
  ```

  ```
  셋 다 같은 결과
  tensor([[1, 2],
          [3, 4]], dtype=torch.int32)
  ```



* 반대로 Tensor를 NumPy 배열로 바꿀 때는 torch.numpy() 메서드를 사용해요

  ```python
  li_tensor.numpy()
  ```

  

### 특정한 값의 텐서 생성

- `torch.arange()` : 주어진 범위 내의 정수를 순서대로 생성
- `torch.ones()` : 주어진 사이즈의 1로 이루어진 텐서 생성
- `torch.zeros()` : 주어진 사이즈의 0으로 이루어진 텐서 생성
- `torch.ones_like()` : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의
- `torch.zeros_like()` : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의
- `torch.linspace()` : 시작점과 끝점을 주어진 갯수만큼 균등하게 나눈 간격점을 행벡터로 출력
- `torch.logspace()` : 시작점과 끝점을 주어진 갯수만큼 로그간격으로 나눈 간격점을 행벡터로 출력



### 랜덤한 값을 가지는 텐서 생성

- `torch.rand()` : 0과 1사이의 숫자를 균등하게 생성
- `torch.rand_like()` : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의
- `torch.randn()` : 평균이 0이고 표준편차가 1인 가우시안 정규분포를 이용해 생성
- `torch.randn_like()` : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의
- `torch.randint()` : 주어진 범위 내의 정수를 균등하게 생성, 자료형은 torch.float32
- `torch.randint_like()` : 사이즈를 튜플로 입력하지 않고 기존의 텐서로 정의
- `torch.randperm()` : 주어진 범위 내의 정수를 랜덤하게 생성



### CUDA Tensors

`.cuda` 메서드를 사용하여 Tensor 자료형을 GPU 상으로 옮길 수 있어요.

```python
x = torch.rand(5, 3)
y = torch.rand(5, 3)

if torch.cuda.is_available():
    x = x.cuda()
    y = y.cuda()
    x + y
```



NumPy 배열과 PyTorch Tensor의 가장 큰 차이점은 PyTorch Tensor는 CPU나 GPU 어디서든 실행가능해요. GPU 연산을 위해, Tensor를 CUDA 자료형으로 변환(Cast) 해주면 돼요.





